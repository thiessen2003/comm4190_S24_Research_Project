
@inproceedings{bender_dangers_2021,
	address = {New York, NY, USA},
	series = {{FAccT} '21},
	title = {On the {Dangers} of {Stochastic} {Parrots}: {Can} {Language} {Models} {Be} {Too} {Big}? ðŸ¦œ},
	isbn = {9781450383097},
	shorttitle = {On the {Dangers} of {Stochastic} {Parrots}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
	doi = {10.1145/3442188.3445922},
	abstract = {The authors discuss the potential dangers of large language models, focusing on issues of bias, fairness, and accountability. The authors argue that the increasing size and complexity of LLMs can lead to the amplification of biases present in the training data and the generation of harmful or misleading outputs. They also highlight the environmental and financial costs associated with training these models and call for greater transparency and responsibility in their development and deployment. This paper is particularly relevant to the research as it directly addresses the challenges associated with LLMs and the need for responsible AI practices. Also, it is quite compelling because it raises important ethical and social considerations in the development of LLMs, which are essential for ensuring that these technologies benefit society as a whole.},
	urldate = {2024-05-15},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	month = mar,
	year = {2021},
	pages = {610--623},
}
